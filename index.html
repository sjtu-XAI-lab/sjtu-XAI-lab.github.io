<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css">
    <link rel="stylesheet" href="https://getbootstrap.com/docs/5.0/examples/sidebars/sidebars.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="style.css">
    <title>Quanshi Zhang | 张拳石</title>
    <link rel="icon" type="image/png" href="img/sjtulogored.png">
</head>

<body>
    <!-- Navbar -->
    <nav class="navbar navbar-expand-lg bg-dark bg-gradient navbar-dark navbar-fixed-top">
        <div class="container">
            <button class="navbar-toggler justify-content-end" type="button" data-bs-toggle="collapse"
                data-bs-target="#navmenu">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse justify-content-end" id="navmenu">
                <ul class="navbar-nav ms-auto">
                    <!-- <div class="nav-li">
                        <a href="#people" class="nav-link">LAB MEMBER</a>
                    </div> -->
                    <div class="nav-li">
                        <a href="#people" class="nav-link">About our Lab</a>
                    </div>
                    <!-- <div class="nav-li">
                        <a href="#news" class="nav-link">NEWS</a>
                    </div> -->
                    <!-- <div class="nav-li">
                        <a href="#research" class="nav-link">RESEARCH MAP</a>
                    </div> -->
                    <div class="nav-li">
                        <a href="#publications" class="nav-link">Publications</a>
                    </div>
                    <div class="nav-li">
                        <a href="#post" class="nav-link">Posts</a>
                    </div>
                    <!-- <div class="nav-li">
                        <a href="#contact" class="nav-link">CONTACT</a>
                    </div> -->
                </ul>
            </div>
            <a href="#" class="navbar-brand px-3">Quanshi Zhang 张拳石 | SJTU interpretable ML lab</a>
        
        </div>
    </nav>

    <!-- Shoucase -->
    <section id="intro" class="bg-dark bg-gradient text-light p-3 text-center">
        <div class="container">
            <div class="row">
                <div class="col-12 px-5 pt-5">
                    <h1>
                        Lab for Interpretability and Theory-Driven Deep Learning
                    </h1>
                </div>
            </div>
        </div>
    </section>


    <!-- People -->
    <section id="people" class="bg-white pb-5 m-0">
        <div class="container">
            <h2 class="text-center text-dark mb-5"> Lab Member</h2>
            <!-- <h3 class="text-dark mb-5"> Team</h3> -->
            <div class="container pb-3 h-100">
                <div class="row d-flex justify-content-center align-lis-center h-100">
                    <div class="col-10">
                        <div class="card border-card">
                            <div class="card-body p-4 bg-white">
                                <div class="d-flex text-black">
                                    <div class="flex-shrink-0">
                                        <img src="img/zqs.png" alt="Generic placeholder image"
                                            class="rounded-circle p-3" style="width: 210px;" />
                                        <div class="text-center">
                                            <span>
                                                <a href="https://scholar.google.com/citations?user=iFFhHK0AAAAJ&hl=zh-CN&oi=ao"
                                                    class="btn btn-default flex-grow-1">Google Scholar</a>
                                                <a href="mailto: zqs1022@sjtu.edu.cn"
                                                    class="btn btn-default flex-grow-1">Email</a>
                                            </span>
                                        </div>
                                    </div>
                                    <div class="flex-grow-1 ms-3">
                                        <h4 class="mb-1 text-center"><strong>Quanshi Zhang</strong></h4>
                                        <p class="text-muted p-0 text-center "
                                            style="text-align:justify; text-justify:inter-ideograph">Principal
                                            Investigator</p>
                                        <p class="mb-2 px-5" style="color: #2b2a2a;">
                                            Currently, I am an associate professor at <a
                                                href="https://en.sjtu.edu.cn/">Shanghai Jiaotong University</a>, leading
                                            the <strong>Lab for Interpretability and Theory-Driven Deep
                                                Learning</strong>.
                                            Before that, I received the B.S. degree in machine intelligence at <a
                                                href="https://english.pku.edu.cn/">Peking University</a>, China, in
                                            2009. I obtained the M.Eng. degree and the
                                            Ph.D. degree at <a href="https://www.u-tokyo.ac.jp/en/">University of
                                                Tokyo</a>, in 2011 and 2014, respectively, under
                                            the supervision of Prof. Ryosuke Shibasaki. In 2014, I became a postdoctoral
                                            associate at the <a href="https://www.ucla.edu/">University of California,
                                                Los Angeles</a>, under the
                                            supervision of <a href="http://www.stat.ucla.edu/~sczhu/">Prof. Song-Chun
                                                Zhu</a>.
                                        </p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="row p-2">
                <div class="col-lg-2"></div>
                <div class="col-lg-2"></div>
                <div class="col-lg-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/huiqideng.png" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Huiqi Deng</strong></h5>
                        <p class="text-muted mb-0"><small>Postdoc</small></p>
                        <span>
                            <a href="https://huiqideng1.netlify.app/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: hqdengsysu@163.com" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-lg-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/wenshen.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Wen Shen</strong></h5>
                        <p class="text-muted mb-0"><small>Postdoc</small></p>
                        <span>
                            <a href="https://ada-shen.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: wen_shen@tongji.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-lg-2"></div>
                <div class="col-lg-2"></div>
            </div>
            <div class="row p-2">
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/xucheng.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Xu Cheng</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <a href="https://cx1208.github.io/ChengXuSJTU.github.io/"
                                class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: xcheng8@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/xinwang.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Xin Wang</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <a href="https://xinwang98.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: xin.wang@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/huilinzhou.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Huilin Zhou</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <a href="https://zhouhuilin116.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: zhouhuilin116@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/jieren.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Jie Ren</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <a href="https://jie-ren.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: ariesrj@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/huixichen.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Huixi Chen</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <!-- <a href="https://nebularaid2000.github.io/" class="btn btn-default btn-sm">Homepage</a> -->
                            <a href="mailto: lural_chen@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/qihanren.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Qihan Ren</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <a href="https://nebularaid2000.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: renqihan@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
            </div>
            <div class="row py-2">
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/siyulou.png" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Siyu Lou</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <a href="https://siyulou.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: siyu.lou@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/yeliu.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Ye Liu</strong></h5>
                        <p class="text-muted mb-0"><small>Phd</small></p>
                        <span>
                            <!-- <a href="https://nebularaid2000.github.io/" class="btn btn-default btn-sm">Homepage</a> -->
                            <a href="mailto: liuye66a@gmail.com" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/dongruiliu.png" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Dongrui Liu</strong></h5>
                        <p class="text-muted mb-0"><small>Internship PhD</small></p>
                        <span>
                            <a href="mailto: drliu96@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/luchen.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Lu Chen</strong></h5>
                        <p class="text-muted mb-0"><small>Internship PhD</small></p>
                        <span>
                            <a href="mailto: lu.chen@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/diezhang.png" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Die Zhang</strong></h5>
                        <p class="text-muted mb-0"><small>Master</small></p>
                        <span>
                            <a href="https://zdgithub.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: zizhan52@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/haozhang.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Hao Zhang</strong></h5>
                        <p class="text-muted mb-0"><small>Master</small></p>
                        <span>
                            <a href="https://haozhang37.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: 1603023-zh@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
            </div>
            <div class="row py-2">

                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/mingjieli.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Mingjie Li</strong></h5>
                        <p class="text-muted mb-0"><small>Master</small></p>
                        <span>
                            <a href="http://mingjie.site/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: limingjie0608@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
                <!-- <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/zhanpengzhou.jpg" class="rounded-circle mb-0" style="height:100px;"
                            alt="Avatar" />
                        <h5 class="mb-0"><strong>Zhanpeng Zhou</strong></h5>
                        <p class="text-muted mb-0"><small>Undergraduate</small></p>
                        <span>
                            <a href="http://zzp1012.top/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: zzp1012@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div> -->

                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/shaobowang.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Shaobo Wang</strong></h5>
                        <p class="text-muted mb-0"><small>Master</small></p>
                        <span>
                            <a href="https://gszfwsb.github.io/" class="btn btn-default btn-sm">Homepage</a>
                            <a href="mailto: shaobowang1009@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>

                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/lingtang.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Ling Tang</strong></h5>
                        <p class="text-muted mb-0"><small>Undergraduate</small></p>
                        <span>
                            <!-- <a href="https://gszfwsb.github.io/" class="btn btn-default btn-sm">Homepage</a> -->
                            <!-- <a href="mailto: 181110315@stu.hit.edu.cn" class="btn btn-default btn-sm">Email</a> -->
                        </span>
                    </div>
                </div>

                <div class="col-2">
                    <div class="p-0" style="text-align: center; vertical-align: middle;">
                        <img src="img/shaobowang.jpg" class="rounded-circle mb-0" style="height:100px;" alt="Avatar" />
                        <h5 class="mb-0"><strong>Shaobo Wang</strong></h5>
                        <p class="text-muted mb-0"><small>Master</small></p>
                        <span>
                            <!-- <a href="https://gszfwsb.github.io/" class="btn btn-default btn-sm">Homepage</a> -->
                            <a href="mailto: void_zxh@sjtu.edu.cn" class="btn btn-default btn-sm">Email</a>
                        </span>
                    </div>
                </div>
            </div>
        </div>

    </section>

    <!-- About Our Lab -->
    <section id="about" class="bg-white text-dark" style="font-family:HelveticaNeue-Light, 'Helvetica Neue Light', 'Helvetica Neue', Helvetica, Arial, 'Lucida Grande', sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 80%;">
        <div class="container margin-right: auto;margin-left: auto; margin-top: 10px;">
            <div class="h2 text-center pb-3">About Our Lab
            </div>
            <p class="px-5" style="text-align:justify; text-justify:inter-ideograph">
                Due to the black-box nature of DNNs, interpretable machine learning has become a
                compelling topic. However, the trustworthiness and applicability of interpretable ML has
                been widely questioned in recent years. Core critisms include the following five aspects.
            <div class="px-5" style="text-align:justify; text-justify:inter-ideograph">
                <ul>
                    <li>Current explanation methods are built upon different heuristics, lacking common theoretical
                        foundations.</li>
                    <li>It is infeasible to objectively evaluate the correctness of the explanation results, in the
                        absence of ground truth explanations.</li>
                    <li>There is still a large gap between the semantic explanation result (e.g., the attribution-based
                        explanation) and the explanation of a DNN’s performance (e.g., the generalization power), which
                        cannot be unified.</li>
                    <li>Traditional semantic explanations cannot be used as feedbacks to guide the designing of DNNs,
                        thereby boosting DNN performances.</li>
                    <li>Most current methods boosting DNN performances are heuristic, and the theoretical mechanisms
                        behind their success are largely missing.</li>
                </ul>
            </div>

            </p>
            <p class="px-5" style="text-align:justify; text-justify:inter-ideograph">
                Therefore, our team aims to solve two key scientific problems:
            <div class="px-5" style="text-align:justify; text-justify:inter-ideograph">
                <ol>
                    <li>how to develop a theoretical system to unify different explanations of the semantics encoded in
                        a DNN (e.g., attribution-based explanations, taxonomy of semantic concepts, and etc) and unify
                        different explanations of the DNN performance (e.g., the generalization power, adversarial
                        robustness, adversarial
                        transferability, and etc). Besides, it is highly desirable to bridge the two types of
                        explanations. We believe that, an explanation system can be considered as trustworthy if the
                        methods in the system can be mutually verified.</li>
                    <li>how to extract the common mechanism behind different heuristic methods, which
                        include both explanation methods and current popular methods boosting the DNN performance.</li>
                </ol>
            </div>
            </p>
    </section>

    <!-- Research Directions -->
    <section id="research" class="p-5 bg-white text-center">
        <div class="h2 text-center">
            Research Map
        </div>
        <div class="text-center" id="interaction_map" style="width:85%; height: 750px; margin-left:10%"></div>
    </section>

    <!-- Publications -->
    <section id="publications" class="p-5 bg-white m-5">
        <div class="h2 text-center">
            Publications
        </div>
        <center>
            <ul class="nav btn-group btn-group-toggle" data-toggle="tabs" role="tablist">
                <button href="#selected" class="btn btn-success active" data-toggle="tab">Interpretability
                    Direction</button>
                <button href="#all" class="btn btn-success" data-toggle="tab">Other Directions</button>
            </ul>
            <div class="tab-content text-center">
                <!-- Selected Publications -->
                <div role="tabpanel" class="tab-pane active" id="selected">
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/preprint-frequency/overview.png" width="80%" />
                            </div>

                            <!-- preprint-2022-frequency -->
                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Defects of Convolutional Decoder Networks in Frequency Representation
                                </strong>
                                <br>
                                Ling Tang, <a href="https://ada-shen.github.io/">Wen Shen</a>, Zhanpeng Zhou, Yuefeng
                                Chen, and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2210.09020" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>


                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/preprint-adv-13/overview.png" width="80%" />
                            </div>

                            <!-- preprint-2022-frequency -->
                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Proving Common Mechanisms Shared by Twelve Methods of Boosting Adversarial
                                    Transferability
                                </strong>
                                <br>
                                <strong>Quanshi Zhang*</strong>, <a href="https://xinwang98.github.io/">Xin Wang*</a>,
                                <a href="https://jie-ren.github.io/">Jie Ren*</a>, <a
                                    href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng*</a>,
                                Shuyun Lin, Yisen Wang, Xiangming Zhu
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2207.11694" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>


                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/preprint-hessian/overview.png" width="80%" />
                            </div>

                            <!-- preprint-2022-frequency -->
                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Batch Normalization Is Blind to the First and Second Derivatives of the Loss
                                </strong>
                                <br>
                                Zhanpeng Zhou, <a href="https://ada-shen.github.io/">Wen Shen</a>, Huixin Chen, Ling
                                Tang, and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2205.15146" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/preprint-adv/overview.png" width="80%" />
                            </div>

                            <!-- preprint-2022-frequency -->
                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Why Adversarial Training of ReLU Networks Is Difficult? </strong>
                                <br>
                                <a href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng*</a>, <a
                                    href="https://haozhang37.github.io/">Hao Zhang*</a>, Yue Xin, <a
                                    href="https://ada-shen.github.io/">Wen Shen</a>, <a
                                    href="https://jie-ren.github.io/">Jie Ren</a>, and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2205.15130" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <!-- <img src="img/publications/icml2022-quantification/overview.png" width="50%" /> -->
                            </div>
                            <!-- icml2022-quantification -->
                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Quantifying the Knowledge in a DNN to Explain Knowledge Distillation for
                                    Classification
                                </strong>
                                <br>
                                <strong>Quanshi Zhang*</strong>, <a
                                    href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng*</a>, Yilan Chen,
                                and Zhefan Rao
                                <br>
                                <div style="color: brown;">IEEE T-PAMI 2022</div>
                                <!-- <a href="https://arxiv.org/abs/1906.04109" class="btn btn-default btn-sm">Paper</a> -->
                            </div>
                        </div>
                    </div>


                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/icml2022-quantification/overview.png" width="50%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Quantification and Analysis of Layer-wise and Pixel-wise Information
                                    Discarding</strong>
                                <br>
                                Haotian Ma*,
                                <a href="https://haozhang37.github.io/">Hao Zhang*</a>,
                                Yinqing Zhang, Fan Zhou, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICML 2022</div>
                                <a href="https://arxiv.org/abs/1906.04109" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- icml2022-trans-complexity -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/icml2022-trans-complexity/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs
                                </strong>
                                <br>
                                <a href="https://jie-ren.github.io/">Jie Ren*</a>, <a
                                    href="https://lmjjjjjj.github.io/">Mingjie Li*</a>,
                                Meng Zhou, Shih-Han
                                Chan, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICML 2022</div>
                                <a href="https://arxiv.org/abs/1906.04109" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- iclr2022-discovering-and-explaining -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/iclr2022-discovering-and-explaining/overview.png"
                                    width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Discovering and Explaining the Representation Bottleneck of DNNs</strong>
                                <br>
                                <a href="https://huiqideng1.netlify.app/">Huiqi Deng*</a>,
                                <a href="https://nebularaid2000.github.io/">Qihan Ren*</a>,
                                <a href="https://haozhang37.github.io/">Hao Zhang</a>,
                                and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICLR 2022 (oral)</div>
                                <a href="https://arxiv.org/abs/2111.06236" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/Nebularaid2000/bottleneck"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="https://zhuanlan.zhihu.com/p/422420088" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                                <a href="https://iclr.cc/virtual/2022/oral/6623" class="btn  btn-default btn-sm">Video
                                    (English)</a>
                                <a href="https://www.bilibili.com/video/BV1gY4y1k7jC?share_source=copy_web"
                                    class="btn  btn-default btn-sm">Techbeat Talk (Chinese)</a>
                            </div>
                        </div>
                    </div>
                    <!-- aistats2022-INN -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/aistats2022-INN/overview.png" width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Exploring Image Regions Not Well Encoded by an INN
                                </strong>
                                <br>
                                <a href="https://zero-lab-pku.github.io/personwise/lingzenan/">Zenan Ling</a>, Fan Zhou,
                                Meng Wei, and <b>Quanshi Zhang</b><br>
                                <div style="color: brown;">AISTATS 2022</div>
                                <a href="https://virtual.aistats.org/virtual/2022/poster/3142"
                                    class="btn btn-default btn-sm">Video (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2022-IGAN -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/aaai2022-IGAN/overview.png" width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpretable Generative Adversarial Networks
                                </strong>
                                <br>
                                Chao Li*, Kelu Yao*, Jin Wang*, Boyu Diao, Yongjun Xu, and <b>Quanshi
                                    Zhang</b>
                                <br>
                                <div style="color: brown;">AAAI 2022 (oral)</div>
                                <a href="https://www.aaai.org/AAAI22Papers/AAAI-7931.LiC.pdf"
                                    class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- preprint - trap -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="./img/publications/preprint-trap/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Trap of Feature Diversity in the Learning of MLPs
                                </strong>
                                <br>
                                Dongrui Liu*,
                                <a href="https://gszfwsb.github.io/">Shaobo Wang*</a>,
                                <a href="https://jie-ren.github.io/">Jie Ren</a>,
                                Kangrui Wang, <br>Sheng Yin,
                                <a href="https://huiqideng1.netlify.app/">Huiqi Deng*</a>,
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2112.00980" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- preprint - AOG -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="./img/publications/preprint-AOG/overview.png" width="55%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep Models
                                </strong>
                                <br>
                                <a href="https://jie-ren.github.io/">Jie Ren*</a>,
                                <a href="https://lmjjjjjj.github.io/">Mingjie Li*</a>,
                                Qirui Chen,
                                <a href="https://huiqideng1.netlify.app/">Huiqi Deng</a>,
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2111.06206" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- preprint - brain -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="./img/publications/preprint-brain/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Rapid Detection and Recognition of Whole Brain Activity in a Freely Behaving
                                    Caenorhabditis Elegans
                                </strong>
                                <br>
                                Yuxiang Wu, Shang Wu, <a href="https://xinwang98.github.io/">Xin Wang</a>, Chengtian
                                Lang, <strong>Quanshi Zhang</strong>, Quan Wen, and Tianqi Xu
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2109.10474" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-aesthetic -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="./img/publications/preprint-aesthetic/overview.png" width="50%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>A Hypothesis for the Aesthetic Appreciation in Neural Networks
                                </strong>
                                <br>
                                <a href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng</a>,
                                <a href="https://xinwang98.github.io/">Xin Wang</a>, Haotian Xue, Zhengyang Liang,
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2108.02646" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-concept -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="./img/publications/preprint-concept/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>A Game-Theoretic Taxonomy of Visual Concepts in DNNs </strong>
                                <br>
                                <a href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng</a>,
                                Chuntung Chu, Yi Zheng, <a href="https://jie-ren.github.io/">Jie Ren</a>
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2106.10938" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-baseline -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="./img/publications/preprint-baseline/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Learning Baseline Values for Shapley Values </strong>
                                <br>
                                <a href="https://jie-ren.github.io/">Jie Ren</a>,
                                <a href="http://zzp1012.top/">Zhanpeng Zhou</a>, Qirui Chen
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2105.10719" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- neurips2021-adv-robustness -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/neurips2021-adv-robustness/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>A Unified Game-Theoretic Interpretation of Adversarial Robustness
                                </strong>
                                <br>
                                <a href="https://jie-ren.github.io/">Jie Ren*</a>,
                                <a href="https://zdgithub.github.io/">Die Zhang*</a>,
                                Yisen Wang*, Lu Chen,
                                <a href="http://zzp1012.top/">Zhanpeng Zhou</a>,
                                Yiting Chen, <br>
                                <a href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng</a>,
                                <a href="https://xinwang98.github.io/">Xin Wang</a>, Meng Zhou, Jie Shi
                                and <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">NeurIPS 2021</div>
                                <a href="https://papers.nips.cc/paper/2021/hash/1f4fe6a4411edc2ff625888b4093e917-Abstract.html"
                                    class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/Jie-Ren/A-Unified-Game-Theoretic-Interpretation-of-Adversarial-Robustness"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="https://zhuanlan.zhihu.com/p/361686461" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                                <a href="https://www.zhihu.com/zvideo/1433604112290537472"
                                    class="btn  btn-default btn-sm">Video (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- neurips2021-visualization -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-10px;">
                                <img src="./img/publications/neurips2021-visualization/overview.png" width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Visualizing the Emergence of Intermediate Visual Patterns in DNNs
                                </strong>
                                <br>
                                <a href="https://lmjjjjjj.github.io/">Mingjie Li</a>,
                                <a href="https://gszfwsb.github.io/">Shaobo Wang</a>,
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">NeurIPS 2021</div>
                                <a href="https://arxiv.org/abs/2111.03505" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://zhuanlan.zhihu.com/p/444149082" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                                <a href="https://www.zhihu.com/zvideo/1433602733882990593"
                                    class="btn btn-default btn-sm">Video
                                    (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- neurips2021-interpreting-the-represenation-quality -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/neurips2021-interpreting-the-represenation-quality/overview.png"
                                    width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting Representation Quality of DNNs for 3D Point Cloud Processing
                                </strong>
                                <br>
                                <a href="https://ada-shen.github.io/">Wen Shen</a>,
                                <a href="https://nebularaid2000.github.io/">Qihan Ren</a>,
                                Dongrui Liu and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">NeurIPS 2021</div>
                                <a href="https://papers.nips.cc/paper/2021/file/4a3e00961a08879c34f91ca0070ea2f5-Paper.pdf"
                                    class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/ada-shen/Interpret_quality"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="https://nips.cc/virtual/2021/poster/27421" class="btn btn-default btn-sm">Video
                                    (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- iccv2021-adv-attribution -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/iccv2021-adv-attack-attribution/overview.png" width="90%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting Attributions and Interactions of Adversarial Attacks
                                </strong>
                                <br>
                                <a href="https://xinwang98.github.io/">Xin Wang*</a>,
                                Shuyun Lin*,
                                Hao Zhang, Yufei Zhu, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICCV 2021</div>
                                <a href="https://arxiv.org/abs/2108.06895#" class="btn btn-default btn-sm">Paper</a>
                                <a href="Code : https://github.com/xinwang98/Interpreting-Attributions-and-Interactions-of-Adversarial-Attacks"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>

                    <!-- icml2021-feature-complexity -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="./img/publications/icml2021-feature-complexity/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting and Disentangling Feature Components of Various Complexity from
                                    DNNs
                                </strong>
                                <br>
                                <a href="https://jie-ren.github.io/">Jie Ren*</a>,
                                <a href="https://lmjjjjjj.github.io/">Mingjie Li*</a>,
                                Zexu Liu,
                                and <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">ICML 2021</div>
                                <a href="http://proceedings.mlr.press/v139/ren21b/ren21b.pdf"
                                    class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/LMJJJJJJ/feature-complexity"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="https://zhuanlan.zhihu.com/p/391220772" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                                <a href="https://www.zhihu.com/zvideo/1433603508231053312"
                                    class="btn btn-default btn-sm">Video
                                    (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- ijcai2021-interpretable-CNN -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="./img/publications/ijcai2021-interpretable-CNN/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpretable Compositional Convolutional Neural Networks
                                </strong>
                                <br>
                                <a href="https://ada-shen.github.io/">Wen Shen*</a>, Zhihua Wei*, Shikun Huang, Binbin
                                Zhang, Jiaqi Fan, Ping Zhao and
                                <strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">IJCAI 2021</div>
                                <a href="https://arxiv.org/abs/2107.04474" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/ada-shen/icCNN" class="btn btn-default btn-sm">Code</a>
                                <a href="https://www.zhihu.com/zvideo/1433605169406095360"
                                    class="btn btn-default btn-sm">Video
                                    (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- cvpr2021-verifiability-predictability -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="./img/publications/cvpr2021-verifiability-predictability/overview.png"
                                    width="75%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Verifiability and Predictability: Interpreting Utilities of Network
                                    Architectures <br>for 3D Point Cloud Processing
                                </strong>
                                <br>
                                <a href="https://ada-shen.github.io/">Wen Shen*</a>, Zhihua Wei*, Shikun Huang, Binbin
                                Zhang, Panyue Chen, Ping Zhao,
                                and <br><strong>Quanshi Zhang</strong>
                                <br>
                                <div style="color: brown;">CVPR 2021</div>
                                <a href="https://arxiv.org/abs/1911.09053" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/ada-shen/utility" class="btn btn-default btn-sm">Code</a>
                                <a href="https://zhuanlan.zhihu.com/p/391220772" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                                <a href="https://www.zhihu.com/zvideo/1433604496211103744"
                                    class="btn btn-default btn-sm">Video
                                    (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- iclr2021-adv-transfer -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/iclr2021-adv-transfer/overview.jpg" width="90%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>A Unified Approach to Interpreting and Boosting Adversarial Transferability
                                </strong>
                                <br>
                                <a href="https://xinwang98.github.io/">Xin Wang*</a>,
                                <a href="https://jie-ren.github.io/">Jie Ren*</a>,
                                Shuyun Lin, Xiangming Zhu,
                                Yisen Wang, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICLR 2021</div>
                                <a href="https://arxiv.org/abs/2010.04055" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/xherdan76/A-Unified-Approach-to-Interpreting-and-Boosting-Adversarial-Transferability"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="#c7" class="btn btn-default btn-sm">Post</a>
                                <a href="https://zhuanlan.zhihu.com/p/369883667" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                            </div>
                        </div>
                    </div>
                    <!-- iclr2021-dropout -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/iclr2021-dropout/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting and Boosting Dropout from a Game-Theoretic View
                                </strong>
                                <br>
                                <a href="https://haozhang37.github.io">Hao Zhang</a>, Sen Li, Yinchao Ma, <a
                                    href="https://lmjjjjjj.github.io/">Mingjie Li</a>,
                                Yichen Xie, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICLR 2021</div>
                                <a href="https://arxiv.org/abs/2009.11729" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2021-shapley-Interactions -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/aaai2021-shapley-Interactions/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting Multivariate Shapley Interactions in DNNs
                                </strong>
                                <br>
                                <a href="https://haozhang37.github.io">Hao Zhang</a>, Yichen Xie, Longjie Zheng, <a
                                    href="https://zdgithub.github.io/">Die
                                    Zhang</a>, <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">AAAI 2021</div>
                                <a href="https://arxiv.org/abs/2010.05045" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/yichen928/Multivariate_Shapley_Interactions"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2021-NLP-Tree -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/aaai2021-NLP-tree/overview.png" width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Building Interpretable Interaction Trees for Deep NLP Models</strong>
                                <br>
                                <a href="https://zdgithub.github.io/">Die Zhang*</a>, <a
                                    href="https://zhouhuilin116.github.io/">Huilin Zhou</a>, <a
                                    href="https://haozhang37.github.io">Hao Zhang</a>, Xiaoyi Bao, Da
                                Huo, Ruizhao Chen, <br><a href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu
                                    Cheng</a>, Mengyue Wu, <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">AAAI 2021</div>
                                <a href="https://arxiv.org/abs/2010.05045" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/zdgithub/Interpretable_Interaction_Trees"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-privacy -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:5px;">
                                <img src="img/publications/preprint-privacy/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Rotation-Equivariant Neural Networks for Privacy Protection </strong>
                                <br>
                                <a href="https://haozhang37.github.io">Hao Zhang</a>, Yiting Chen, Haotian Ma, <a
                                    href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng</a>,
                                <a href="https://nebularaid2000.github.io/">Qihan Ren</a>, <br>
                                Liyao Xiang, Jie Shi and <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2006.13016" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-quaternion -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-10px;">
                                <img src="img/publications/preprint-quaternion/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Deep Quaternion Features for Privacy Protection
                                </strong>
                                <br>
                                <a href="https://haozhang37.github.io">Hao Zhang</a>, Yiting Chen, Liyao Xiang, Haotian
                                Ma, Jie Shi and <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/2003.08365" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- eccv2020-3D-Rotation -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/eccv2020-3D-Rotation/overview.png" width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>3D-Rotation-Equivariant Quaternion Neural Networks</strong>
                                <br>
                                Binbin Zhang, <a href="https://ada-shen.github.io/">Wen Shen</a>, Shikun Huang, Zhihua
                                Wei, and <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">ECCV 2020 </div>
                                <a href="https://arxiv.org/abs/2010.05045" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/ada-shen/REQNN" class="btn btn-default btn-sm">Code</a>
                                <a href="https://www.zhihu.com/zvideo/1433604790786248704"
                                    class="btn btn-default btn-sm">Video (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- tpami-2020-CNN-object -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/pami-2020-CNN-object/overview.gif" width="40%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpretable CNNs for Object Classification
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>,
                                <a href="https://xinwang98.github.io/">Xin Wang*</a>,
                                Ying Nian Wu, <a href="https://zhouhuilin116.github.io/">Huilin Zhou</a>, and Song-Chun
                                Zhu
                                <div style="color: brown;">IEEE T-PAMI, 2020</div>
                                <a href="https://arxiv.org/abs/1901.02413" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.hk01.bdysite.com/index.php/icnn/"
                                    class="btn btn-default btn-sm">Project Website</a>
                                <a href="https://github.com/zqs1022/interpretableCNN"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>
                    <!-- tpami-2020-explanatory-graph  -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/pami-2020-explanatory-graph/overview.jpg" width="40%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Extraction of an Explanatory Graph to Interpret a CNN
                                </strong>
                                <br>

                                <strong>Quanshi Zhang</strong>,
                                <a href="https://xinwang98.github.io/">Xin Wang*</a>, Ruiming Cao,
                                Ying Nian Wu, Feng Shi, and Song-Chun Zhu
                                <div style="color: brown;">IEEE T-PAMI, 2020</div>
                                <a href="https://arxiv.org/abs/1812.07997" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.com/index.php/explanatorygraph/"
                                    class="btn btn-default btn-sm">Project Website</a>
                                <a href="https://github.com/zqs1022/explanatoryGraph"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="http://qszhang.com/files/video/demo_CNN-ExplanatoryGraph-AOG.mp4"
                                    class="btn btn-default btn-sm">Video (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- tpami-2021-explanatory-graph  -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/pami2020-AOG/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Mining Interpretable AOG Representations from Convolutional Networks via Active
                                    Question Answering
                                </strong>
                                <br>

                                <strong>Quanshi Zhang</strong>,
                                <a href="https://jie-ren.github.io/">Jie Ren</a>, Ge Huang, Ruiming Cao, Ying Nian Wu,
                                and Song-Chun Zhu
                                <div style="color: brown;">IEEE T-PAMI, 2020</div>
                                <a href="https://arxiv.org/abs/1812.07996" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-evaluation -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:15px;">
                                <img src="img/publications/preprint-evaluation/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Towards a Unified Evaluation of Explanation Methods without Ground Truth
                                </strong>
                                <br>
                                <a href="https://haozhang37.github.io">Hao Zhang</a>, Jiayi Chen, Haotian Xue, and
                                <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/1911.09017" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- preprint-AlphaGo -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:15px;">
                                <img src="img/publications/preprint-AlphaGo/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks

                                </strong>
                                <br>
                                <a href="https://zero-lab-pku.github.io/personwise/lingzenan/">Zenan Ling</a>, Haotian
                                Ma, Yu Yang, Robert C. Qiu1, Song-Chun Zhu, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">Preprint</div>
                                <a href="https://arxiv.org/abs/1901.02184" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>


                    <!-- iccv2019-explain-NN -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-15px;">
                                <img src="img/publications/cvpr2020-distillation/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Explaining Knowledge Distillation by Quantifying the Knowledge
                                </strong>
                                <br>
                                <a href="https://cx1208.github.io/ChengXuSJTU.github.io/">Xu Cheng</a>, Zhefan Rao,
                                Yilan Chen, and <strong>Quanshi Zhang</strong><br>
                                <div style="color: brown;">CVPR 2020</div>
                                <a href="https://arxiv.org/abs/1812.07169" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/Jenniferlyx/Explaining-Knowledge-Distillation-by-Quantifying-the-Knowledge"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="https://zhuanlan.zhihu.com/p/113811002" class="btn btn-default btn-sm">Blog
                                    (Chinese)</a>
                            </div>
                        </div>
                    </div>
                    <!-- ICLR2020-knowledge-consistency -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/iclr2020-knowledge-consistency/overview.png" width="70%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Knowledge Consistency between Neural Networks and Beyond
                                </strong>
                                <br>
                                Ruofan Liang, Tianlin Li, Longfei Li, Jing Wang, and <b>Quanshi Zhang</b><br>
                                <div style="color: brown;">ICLR 2020</div>
                                <a href="https://arxiv.org/abs/1908.01581" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/nexuslrf/knowledge_consistency"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="https://www.jiqizhixin.com/articles/2020-01-11-3"
                                    class="btn btn-default btn-sm">Synced News (Chinese)</a>
                            </div>
                        </div>
                    </div>
                    <!-- ICLR2020-privacy -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/iclr2020-privacy/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpretable Complex-Valued Neural Networks for Privacy Protection
                                </strong>
                                <br>
                                Liyao Xiang, <a href="https://haozhang37.github.io">Hao Zhang</a>, Haotian Ma, Yifan
                                Zhang, <a href="https://jie-ren.github.io/">Jie Ren</a>, and <b>Quanshi Zhang</b><br>
                                <div style="color: brown;">ICLR 2020</div>
                                <a href="https://arxiv.org/abs/1901.09546" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- iccv2019-explain-NN -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-15px;">
                                <img src="img/publications/iccv2019-explain-NN/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Explaining Neural Networks Semantically and Quantitatively
                                </strong>
                                <br>
                                <a href="https://chenrunjin.github.io/">Runjin Chen</a>,
                                Hao Chen,
                                <a href="https://jie-ren.github.io/">Jie Ren</a>,
                                Ge Huang, and <strong>Quanshi
                                    Zhang</strong><br>
                                <div style="color: brown;">ICCV 2019 (oral)</div>
                                <a href="https://arxiv.org/abs/1812.07169" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- icml2019-NLP -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/icml2019-NLP/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Towards A Deep and Unified Understanding of Deep Neural Models in NLP
                                </strong>
                                <br>
                                Chaoyu Guan*, Xiting Wang*, <strong>Quanshi
                                    Zhang</strong>, <a href="https://chenrunjin.github.io/">Runjin Chen</a>, Di He, Xing
                                Xie <br>
                                <div style="color: brown;">ICML 2019</div>
                                <a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/05/camera_paper_with_supp_3.pdf"
                                    class="btn btn-default btn-sm">Paper</a>
                                <a href="https://github.com/icml2019paper2428/Towards-A-Deep-and-Unified-Understanding-of-Deep-Neural-Models-in-NLP"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>
                    <!-- cvpr2019-decision-tree -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-10px;">
                                <img src="img/publications/cvpr2019-decision-tree/overview.png" width="50%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting CNNs via Decision Trees
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>, Yu Yang, Haotian Ma, and Ying Nian Wu <br>
                                <div style="color: brown;">CVPR 2019</div>
                                <a href="https://arxiv.org/abs/1802.00121" class="btn btn-default btn-sm">Paper</a>
                                <a href="https://www.jiqizhixin.com/articles/0211" class="btn btn-default btn-sm">Synced
                                    News (Chinese)</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2019-workshop-->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/aaai19-workshop-unsupervise/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Unsupervised Learning of Neural Networks to
                                    Explain Neural Networks
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>, Yu Yang, Yuchen Liu, Ying Nian Wu, and Song-Chun Zhu
                                <br>
                                <div style="color: brown;">AAAI 2019 Workshop</div>
                                <a href="https://arxiv.org/abs/1805.07468" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2019-workshop-->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:10px;">
                                <img src="img/publications/aaai19-workshop-transplanting/overview.png" width="90%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Network Transplanting
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>, Yu Yang, Qian Yu, Ying Nian Wu, and Song-Chun Zhu
                                <br>
                                <div style="color: brown;">AAAI 2019 Workshop</div>
                                <a href="https://arxiv.org/abs/1804.10272" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>
                    <!-- CVPR (Spotlight) 2018(tpami-2020-CNN-object) -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/pami-2020-CNN-object/overview.gif" width="40%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpretable Convolutional Neural Networks</strong>
                                <br>
                                <strong>Quanshi Zhang</strong>,
                                Ying Nian Wu, and Song-Chun Zhu
                                <div style="color: brown;">CVPR (Spotlight) 2018 </div>
                                <a href="https://arxiv.org/abs/1710.00935" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.hk01.bdysite.com/index.php/icnn/"
                                    class="btn btn-default btn-sm">Project Website</a>
                                <a href="https://github.com/zqs1022/interpretableCNN"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2018-explanatory-graph(tpami-2020-explanatory-graph)  -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/pami-2020-explanatory-graph/overview.jpg" width="40%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interpreting CNN Knowledge via an Explanatory Graph

                                </strong>
                                <br>

                                <strong>Quanshi Zhang</strong>,
                                Ruiming Cao, Feng Shi, Ying Nian Wu, and
                                Song-Chun Zhu
                                <div style="color: brown;">AAAI 2018</div>
                                <a href="https://arxiv.org/abs/1812.07997" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.com/index.php/explanatorygraph/"
                                    class="btn btn-default btn-sm">Project Website</a>
                                <a href="https://github.com/zqs1022/explanatoryGraph"
                                    class="btn btn-default btn-sm">Code</a>
                                <a href="http://qszhang.com/files/video/demo_CNN-ExplanatoryGraph-AOG.mp4"
                                    class="btn btn-default btn-sm">Video (English)</a>
                            </div>
                        </div>
                    </div>

                    <!-- aaai2018-dataset-bias -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-10px;">
                                <img src="img/publications/aaai18-dataset-bias/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Examining CNN Representations with respect to Dataset Bias
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>,
                                Wenguan Wang, and Song-Chun Zhu
                                <div style="color: brown;">AAAI 2018</div>
                                <a href="https://arxiv.org/abs/1710.10577" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>


                    <!-- cvpr2017-QA -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-10px;">
                                <img src="img/publications/cvpr2017-QA/overview.png" width="50%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Mining Object Parts from CNNs via Active Question-Answering

                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>,
                                Ruiming Cao, Ying Nian Wu, and Song-Chun Zhu
                                <div style="color: brown;">CVPR 2017</div>
                                <a href="http://arxiv.org/abs/1704.03173" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.com/index.php/convpart/" class="btn btn-default btn-sm">Project
                                    Website</a>
                                <a href="http://qszhang.com/files/video/demo_QA.mp4"
                                    class="btn btn-default btn-sm">Video (English)</a>
                            </div>
                        </div>
                    </div>
                    <!-- aaai2017-Multi-Shot -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:-10px;">
                                <img src="img/publications/aaai2017-Multi-Shot/overview.png" width="80%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Growing Interpretable Part Graphs on ConvNets via Multi-Shot Learning
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>,
                                Ruiming Cao, Ying Nian Wu, and Song-Chun Zhu
                                <div style="color: brown;">AAAI 2017</div>
                                <a href="https://arxiv.org/abs/1611.04246" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.com/index.php/cnnsemantics/"
                                    class="btn btn-default btn-sm">Project
                                    Website</a>
                                <a href="http://qszhang.com/files/video/demo_CNN-ExplanatoryGraph-AOG.mp4"
                                    class="btn btn-default btn-sm">Video (English)</a>
                                <a href="https://github.com/zqs1022/partGraphForCNN"
                                    class="btn btn-default btn-sm">Code</a>
                            </div>
                        </div>
                    </div>


                    <!-- preprint-localization -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/preprint-localization/overview.png" width="60%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Interactively Transferring CNN Patterns for Part Localization
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>, Ruiming Cao, Shengming Zhang, Ying Nian Wu, and
                                Song-Chun Zhu
                                <div style="color: brown;">preprint</div>
                                <a href="https://arxiv.org/abs/1708.01783" class="btn btn-default btn-sm">Paper</a>
                            </div>
                        </div>
                    </div>

                    <!-- survey -->
                    <div class="container" style="margin-top: 30px;">
                        <div class="row">
                            <div class="col-xs-12 col-lg-4 img_responsive"
                                style="text-align: center; vertical-align: middle; margin-top:0px;">
                                <img src="img/publications/survey/overview.png" width="100%" />
                            </div>

                            <div class="col-xs-12 col-lg-8" style="text-align: left; vertical-align: middle;">
                                <strong>Visual interpretability for Deep Learning: a Survey
                                </strong>
                                <br>
                                <strong>Quanshi Zhang</strong>, and Song-Chun Zhu
                                <div style="color: brown;">Frontiers of Information Technology & Electronic
                                    Engineering.<br>
                                    Vol. 19, No. 1, page 27-39, 2018 (best paper)
                                </div>
                                <a href="https://arxiv.org/abs/1802.00614" class="btn btn-default btn-sm">Paper</a>
                                <a href="http://qszhang.com/index.php/visualinterpretability/"
                                    class="btn btn-default btn-sm">Project
                                    Website</a>
                                <a href="https://www.jiqizhixin.com/articles/030205"
                                    class="btn btn-default btn-sm">Synced News (Chinese)</a>
                            </div>
                        </div>

                    </div>
                </div>
                <!-- All Publications -->
                <div role="tabpanel" class="tab-pane text-left" id="all">
                    <div
                        style="margin-right: auto;margin-left: auto; margin-top: 10px; margin-bottom: 100px; width: 70%; font-family:'HelveticaNeue-Light', 'Helvetica Neue Light', 'Helvetica Neue', Helvetica, Arial, 'Lucida Grande', sans-serif">
                        <ol>
                            <!-- graph -->
                            <li>
                                <b>Visual Graph Mining for Graph Matching
                                    <a href="https://arxiv.org/abs/1708.03921" class="default">[Paper]</a></b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Yu Yang, Haotian Ma, Ryosuke Shibasaki
                                <br>
                                Computer Vision and Image Understanding, vol. 178, page 16-29, 2019
                            </li><br>
                            <li>
                                <b>Mining Deep And-Or Object Structures via Cost-Sensitive Question-Answer-Based
                                    Active
                                    Annotations <a href="https://arxiv.org/abs/1708.03911" class="default">[Paper]</a>
                                </b><br>
                                <b>Quanshi Zhang</b>, Ying Nian Wu, Hao Zhang, and Song-Chun Zhu<br>
                                Computer Vision and Image Understanding, vol. 176-177, page 33-44, 2018
                            </li><br>
                            <li>
                                <b>Object Discovery: Soft Attributed Graph Mining
                                    <a href="http://qszhang.com/publications/pami2016.pdf" class="default">[Paper]</a>
                                    <a href="http://qszhang.com/index.php/msap/" class="default">[Project
                                        Website]</a>
                                    <a href="https://github.com/zqs1022/mSAP" class="default">[Code]</a>
                                </b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke
                                Shibasaki<br>
                                IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
                                38(3):532-545,
                                2016
                            </li><br>
                            <li>
                                <b>From RGB-D Images to RGB Images: Single Labeling for Mining Visual
                                    Models <a href="http://qszhang.com/publications/tist2015.pdf"
                                        class="default">[Paper]</a></b><br>
                                <b>Quanshi Zhang,
                                </b>Xuan Song, Xiaowei Shao, Ryosuke Shibasaki, Huijing Zhao<br>
                                ACM Transactions on Intelligent Systems and Technology (ACM-TIST), 6(2): 16, 2015
                            </li><br>
                            <li>
                                <b>Mining And-Or Graphs for Graph Matching and Object Discovery</b><br>
                                <b>Quanshi Zhang</b>, Ying Nian Wu, and Song-Chun Zhu<br>
                                ICCV 2015
                            </li><br>
                            <li>
                                <b>Attributed Graph Mining and Matching: An Attempt to Define and Extract Soft
                                    Attributed Patterns</b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke Shibasaki
                                <br>
                                CVPR 2014
                            </li><br>

                            <li>
                                <b>Learning Graph Matching: Oriented to Category Modeling from Cluttered
                                    Scenes</b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke
                                Shibasaki<br>
                                ICCV 2013
                            </li><br>
                            <li>
                                <b>Category Modeling from just a Single Labeling: Use Depth Information to Guide the
                                    Learning of 2D Models</b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke
                                Shibasaki<br>
                                CVPR 2013
                            </li><br>
                            <!-- direction 3 -->
                            <li>
                                <b> Prediction and Simulation of Human Mobility Following Natural Disasters
                                </b><br>
                                Xuan Song, <b>Quanshi Zhang</b>, Yoshihide Sekimoto, Ryosuke Shibasaki, Nicholas
                                Jing
                                Yuan, and Xing Xie<br>
                                ACM Transactions on Intelligent Systems and Technology (ACM-TIST), 8(2): 29, 2016
                            </li><br>
                            <li>
                                <b> Unsupervised Skeleton Extraction and Motion Capture from 3D Deformable
                                    Matching</b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Ryosuke Shibasaki, and Huijing
                                Zhao<br>
                                Neurocomputing, Elsevier, pp.170-182, 2013
                            </li><br>
                            <li>
                                <b> Intelligent System for Human Behavior Analysis and Reasoning Following
                                    Large‐scale
                                    Disasters</b><br>
                                Xuan Song, <b> Quanshi Zhang</b>, Yoshihide Sekimoto, Teerayut Horanont, Satoshi
                                Ueyama,
                                and Ryosuke
                                Shibasaki<br>
                                IEEE Intelligent Systems, vol. 28, no. 4, pp. 35-42, July-Aug. 2013
                            </li><br>
                            <li>
                                <b>A Fully Online and Unsupervised System for Large and High Density Area
                                    Surveillance:
                                    Tracking, Semantic Scene Learning and Abnormality Detection</b><br>
                                Xuan Song, Xiaowei Shao, <b>Quanshi Zhang</b>, Ryosuke Shibasaki, Huijing Zhao,
                                Jinshi
                                Cui, and Hongbin Zha><br>
                                ACM Transactions on Intelligent Systems and Technology (ACM‐TIST), 4(2): 20, 2013
                            </li><br>


                            <li>
                                <b> A Novel Dynamic Model for Multiple Pedestrians Tracking in Extremely Crowded
                                    Scenarios</b><br>
                                Xuan Song, Xiaowei Shao, <b> Quanshi Zhang</b>, Ryosuke Shibasaki, Huijing Zhao, and
                                Hongbin Zha<br>
                                Information Fusion, Elsevier, 2012
                            </li><br>

                            <li>
                                <b>
                                    A Simulator of Human Emergency Mobility following Disasters: Knowledge Transfer
                                    from
                                    Big Disaster Data</b><br>
                                Xuan Song, <b>Quanshi Zhang</b>, Yoshihide Sekimoto, Ryosuke Shibasaki, Nicholas
                                Jing
                                Yuan, and Xing Xie<br>
                                AAAI 2015
                            </li><br>
                            <li>
                                <b> When 3D Reconstruction Meets Ubiquitous RGB-D Images
                                </b><br>
                                <b> Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke Shibasaki
                                <br>
                                CVPR 2014
                            </li><br>
                            <li>
                                <b> Start from Minimum Labeling: Learning of 3D Object Models and Point Labeling
                                    from a
                                    Large
                                    and Complex Environment</b><br>
                                <b> Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke Shibasaki
                                <br>
                                ICRA 2014
                            </li><br>
                            <li>
                                <b> Prediction of Human Emergency Behavior and their Mobility following Large-scale
                                    Disaster</b><br>
                                Xuan Song, <b>Quanshi Zhang</b>, Yoshihide Sekimoto, and Ryosuke Shibasaki <br>
                                KDD 2014

                            </li><br>
                            <li>
                                <b> Intelligent System for Urban Emergency Management During Large-scale
                                    Disaster</b><br>
                                Xuan Song,<b>Quanshi Zhang</b>, Yoshihide Sekimoto, and Ryosuke Shibasaki<br>
                                AAAI 2014
                            </li><br>
                            <li>
                                <b> Unsupervised 3D Category Discovery and Point Labeling from a Large Urban
                                    Environment</b><br>
                                <b>Quanshi Zhang</b>, Xuan Song, Xiaowei Shao, Huijing Zhao, and Ryosuke
                                Shibasaki<br>
                                ICRA 2013
                            </li><br>
                            <li>
                                <b> Modeling and Probabilistic Reasoning of Population Evacuation During Large-scale
                                    Disaster</b><br>
                                Xuan Song, <b>Quanshi Zhang</b>, Yoshihide Sekimoto, Teerayut Horanont, Satoshi
                                Ueyama,
                                and Ryosuke Shibasaki<br>
                                KDD 2013
                            </li><br>
                            <li>
                                <b> Laser-based Intelligent Surveillance and Abnormality Detection in Extremely
                                    Crowded
                                    Scenarios</b><br>
                                Xuan Song, Xiaowei Shao, <b>Quanshi Zhang</b>, Ryosuke Shibasaki, Huijing Zhao, and
                                Hongbin Zha<br>
                                ICRA 2012
                            </li><br>
                            <li>
                                <b> Moving Object Classification using Horizontal Laser Scan Data
                                </b><br>
                                Huijing Zhao, <b>Quanshi Zhang</b>, Masaki Chiba, Ryosuke Shibasaki, Jinshi Cui, and
                                Hongbin Zha<br>
                                ICRA 2009
                            </li>
                        </ol>
                    </div>
                </div>
            </div>
        </center>

    </section>


    <!-- Blog -->
    <section id="post" class="p-5 bg-white" style="font-family:HelveticaNeue-Light, Helvetica Neue Light, Helvetica Neue, Helvetica, Arial, Lucida Grande, sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;">
        <div class="h2 text-center">Research Post</div>
        <div
            style="margin-right: auto;margin-left: auto; margin-top: 10px; margin-bottom: 100px; width: 70%;text-align:justify; text-justify:inter-ideograph">
            <div style="text-align: center;">
                <h3 id="Interaction">Interaction Interpretability of Neural Networks</h3>
            </div>
            <p id="c1"><br><br></p>
            <h4><strong> Chapter 1 Introduction</strong> </h4>
            <p>
                In 2018, I started to post on the online platform <a
                    href=" https://zhuanlan.zhihu.com/p/264871522/">"Zhihu"</a> (similar
                to
                Quora) for my research about
                the interpretability of DNNs. At that point my paper was finally accepted for the first time after being
                repeatedly discouraged by the trend of pursuing higher prediction scores on a certain task. Only then
                can I
                say it out loud “beyond visualization, there is another path to interpretability.” Two years later, I
                still
                insist on posting, because I want everyone to know if all explanation methods are only self-justified,
                but
                cannot be verified by each other, then neither of them can be considered as a fully correct method.
                There
                are only a few solid studies in Explainable AI, such as the Shapley value, which satisfies four
                mathematical
                axioms for a "correct attribution heatmap", including linearity, nullity, symmetry, and efficiency.
                Explanations that satisfy the above four axioms can be considered as rigorous explanations. If there is
                no
                theory to ensure the rigor and objectivity of explanation methods, then sooner or later the
                interpretation
                research will disappear.
                (Note that this is not an article to discourage you from doing research on Explainable AI. I am
                semi-confident in the future of explainable AI —— there is a chance that nothing you will achieve, that
                you
                will end up with publishing some papers, or that you will actually do some solid work. This is sometimes
                the
                most exciting and promising research. Therefore, I still keep going.)
            </p>
            <p>The "objective rigor" of interpretability often means "generality" and "uniqueness", i.e., "the
                explanation
                of the only standard. "Generality" is easy to understand, which means that the algorithm should be more
                standard and have more connections to previous theories, rather than being a scenario-specific ad-hoc
                technique. In contrast, the "uniqueness" has been rarely mentioned, some people even ask "why should the
                explanation be unique?" Here we need to impose some restrictions on "what is a good explanation？" E.g.,
                what
                conditions must be satisfied by a good explanation, and then "uniqueness" is embodied in the unique
                solution
                under these conditions. To a smaller extent, conditions for explanations can be the four axioms
                corresponding to the Shapley value; to a larger extent, conditions for explanations can also be the
                scope of
                application of the interpretability metrics. For example, the same metric can "explain semantics,
                generalization, and transferability".
                <!-- <div class="p-5 text-center" style="text-align:center; width:100%">
                <iframe width="800" height="400" src="https://www.youtube.com/embed/DEvI5silI4Q"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
                <figcaption class="pt-3 px-3 card-img-bottom">
                    <h2 class="h5 font-weight-bold mb-2 font-italic">Video 1</h2>
                    <p class="mb-0 text-small text-muted font-italic">Lorem ipsum dolor sit amet, consectetur
                        adipisicing
                        elit, sed do eiusmod tempor.</p>
                </figcaption>
            </div> -->
            </p>
            <p>
                Let's jump out of the topic that we just discussed and now let's face the whole picture of explainable
                AI.
                Whether a research direction is "alive" or "sustainable in the future" does not lie in the number of
                papers
                published in the field, nor in the number of citations, but in the number of essential problems in the
                research direction that have not been addressed mathematically. (Here we refer to the solid modeling,
                rather
                than deliberately hooking up a new concept). After all, I still remember the saying by Professor
                Song-Chun
                Zhu "deep learning has died" in 2006, a sentence enough for me to digest for many years - when a person
                blocks all the shortcuts for publishing papers, you need to plan a road from the mud, which may be the
                right
                way to go - although it is likely to die on the halfway, we have to be prepared.<br>
            </p>
            <p>Now, let's go back to talk about the explainable AI. The original purpose of explainable AI is very
                simple,
                that is, to provide theoretical guidance for the training and design of neural networks, and to test the
                reliability of the information modeled by neural networks. In brief, a reliable explainable AI study
                needs
                to satisfy requirements simultaneously:
            <ol>
                <li>Direct theoretical modeling of the target to be explained is required, rather than proposing
                    indirect
                    algorithms intuitively.</li>
                <li>Quantitative explanatory results are needed, instead of qualitative ones.</li>
                <li>The objectivity (or rigor) of the explanatory results needs to be evaluated, rather than just
                    requiring
                    that the explanatory results look good.</li>
                <li>For many emerging problems in explainable AI, sometimes we cannot provide a direct evaluation or the
                    ground-truth of neural networks. Thus, we need a more solid theoretical system to prove the rigor of
                    mathematical modeling.
                    <ul>
                        <li>For example, the rigor of Shapley value is guaranteed by the four axioms it satisfies.
                            Similarly, an explanation method needs to satisfy a large number of axioms or exhibits good
                            properties to demonstrate the rigor of the explanation method.</li>
                        <li>Besides, if different explanation methods or metrics can be mutually validated, then such
                            explanations are often more rigorous.</li>
                    </ul>
                </li>
                <li>Explanation theories need to be extended to explaining various phenomena in real-world applications,
                    or
                    to provide direct guidance on the design and training of neural networks.</li>
            </ol>
            </p>
            <p id="c2"><br><br></p>
            <h4><strong>Chapter 2</strong></h4>
            <p id="c3"><br><br></p>
            <h4><strong>Chapter 3</strong></h4>
            <p id="c4"><br><br></p>
            <h4><strong>Chapter 4</strong></h4>
            <p id="c5"><br><br></p>
            <h4><strong>Chapter 5</strong></h4>
            <p id="c6"><br><br></p>
            <h4><strong>Chapter 6</strong></h4>
            <p id="c7"><br><br></p>
            <h4><strong> Chapter 7 From Practice to Theory: Adversarial Transferability of Neural
                    Networks</strong> </h4>
            <h4><strong>Introduction</strong></h4>
            <p>
                Hello, we are Xin Wang and Jie Ren, students of Dr. Quanshi Zhang. In this article, we would like to
                share some new insights to adversarial transferability of DNNs.
            </p>
            <p>
                Reference: Xin Wang, Jie Ren, Shuyun Lin, Xiangming Zhu, Yisen Wang, Quanshi Zhang, <a
                    href="https://arxiv.org/abs/2010.04055">"A Unified
                    Approach to Interpreting and Boosting Adversarial Transferability"</a> in ICLR 2021
            </p>
            <p><i>—— Note that this paper is not based on empirical experiments, instead, we investigated the nature of
                    adversarial transferability of DNN (though not very rigorously), while the experiments serve as an
                    aid to verification. Please pay attention to this.</i></p>
            <p>
                Although deep learning has been rapidly developed in the last decades, they have encountered
                bottlenecks. On the one hand, many algorithms are proposed based on trial and error from empirical
                experiments, which lack solid and reliable theoretical foundations; on the other hand, these studies
                usually based on simple assumptions, which are detached from the actual problems and cannot guide the
                design and optimization of DNNs.
            </p>
            <p>
                Therefore, we believe the new trend for deep learning is to build a complete theoretical system and use
                it to guide applications. If an algorithm only stays at the experimental level without theoretical
                explanation, then such an algorithm just like “Shennong”, a divine farmer in ancient China, who tasted
                hundreds of herbs to test their medical value. People cannot explain why such an algorithm works, then
                the significance of the algorithm might be limited to make a small improvement on performance, which
                constrains further explorations. In contrast, if we can prove and grasp the common effective components
                shared by many different algorithms, just like deriving the common effective ingredients from hundreds
                of herbs, then the algorithm can be considered effective and reliable. Thus, these insights can be used
                to guide the design of network structure and improve the performance of DNNs.
            </p>
            <p>In this article, we take the adversarial transferability of DNNs as an example to made attempts along
                this direction. We have obtained some shallow conclusions to suggest possible explanations for the
                previous algorithms that were proposed to improve the adversarial transferability. We hope to extract
                some common effects in previous algorithms, and further improve the algorithm transferability. Although
                we cannot ensure that these conclusions essentially reflect the nature of adversarial transferability,
                we try to ensure that our results reflect some of the common effects of previous algorithms. Besides,
                taking this study as a basis, we further explore the intrinsic nature of adversarial transferability.
            </p>
            <h4><strong>Enhancing adversarial transferability: from practice to theory</strong></h4>
            <p>
                In recent years, adversarial samples have attracted much attention in the field of deep learning. Behind
                the superior performance of neural networks, there lies a very dangerous security risk —— adding a small
                imperceptible perturbation to the input sample can completely change the prediction of a neural network.
                Such maliciously modified input samples are called adversarial samples. Researchers also found that
                these adversarial samples are transferable, which means that an adversarial sample generated on neural
                network A may also be able to attack neural network B.
            </p>
            <p>
                Many approaches have been proposed to enhance the adversarial transferability. However, the intrinsic
                mechanism of these methods to enhance the transferability remains unclear, just like different herbs
                tasted by Shennong. Although these methods can indeed enhance transferability, people are still unclear
                about which components that really work. Here we summarize several common approaches to enhance
                transferability.
            <ul>
                <li><strong>Variance-Reduced Attack (VR Attack)</strong>: During the attack, Gaussian noise is added to
                    the input image to smooth the gradient against the input image.</li>
                <li><strong>Momentum Iterative Attack (MI Attack)</strong>: Integrate the gradient momentum in the
                    optimization of adversarial perturbations.</li>
                <li><strong>Skip Connection Method (SGM Attack)</strong>: For the residual block structure of the
                    network, increase the gradient weight of the skip-connection branch in the backpropagation process.
                </li>
                <li><strong>Diversity Input Attack (DI Attack)</strong>: During the attack, introduce random padding and
                    random resizing on the input image to increase the diversity.</li>
                <li><strong>Translation Invariant Attack (TI Attack)</strong>: Convolve the image gradient during the
                    attack.</li>
            </ul>
            Our goal is to extract the common effects from the above methods.
            </p>
            <h4><strong>Adversarial Transferability: Extraction of useful components</strong></h4>
            <p>We aim to explain adversarial transferability from a new perspective, the game-theoretic interaction
                inside the adversarial perturbation. This explanation further extracts the common effects of the
                previous transferability-boosting approaches.</p>
            <h4><strong>Basis: Game-theoretic interaction</strong></h4>
            <p>We define the game-theoretic interaction between two units of the adversarial perturbation based on the
                Shapley value in game theory. Shapley values measure the importance of different adversarial
                perturbation units. For two adversarial perturbation units i and j, the game-theoretic interaction
                between them embodies the influence of i and j on each other, which can be defined as: the importance of
                i when j is always present minus the importance of i when j is not present. If the interaction is
                greater than 0, it means that there is a positive interaction between i and j, which facilitates the
                importance of each other. If the interaction is less than 0, it means that there is a negative
                interaction between i and j, which decreases the importance of each other.</p>
            <h4><strong>Motivation: multi-step attack vs. single-step attack</strong></h4>
            <p>Previous studies have suggested that, compared with the single-step attacks, the adversarial
                perturbations generated by multi-step attacks are more likely to overfit to the source neural network,
                which result in lower transferability. We analyzed multi-step attacks and single-step attacks from the
                perspective of game-theoretic interactions, and deduced that the adversarial perturbations obtained from
                multi-step adversarial attacks usually exhibit larger game-theoretic interactions than those obtained
                from single-step attacks.</p>
            <h4><strong>Hypothesis: there is a negative correlation between adversarial transferability and
                    game-theoretic interaction</strong></h4>
            <p>For single-step and multi-step attacks, we observed that:
            <ul>
                <li>Adversarial transferability: multi-step attack < single-step attack</li>
                <li>Game-theoretic interaction: multi-step attack > single-step attack</li>
            </ul>
            <p>
                Based on the above observations, we consider that the complex game-theoretic interactions reveal the
                overfitting of the adversarial perturbations towards the source model, thus compromising its
                transferability to the target network. Thus, we propose the following hypothesis.<br>
            <blockquote style="font-size:medium">
                The transferability of the adversarial perturbation is negatively correlated with the
                interaction inside the perturbation.
            </blockquote>

            </p>
            <h4><strong>Verification: Negative correlation between adversarial transferability and game-theoretic
                    interaction</strong></h4>
            <p>We empirically compare the interactions of the less transferable adversarial perturbations with those of
                the more transferable ones, and thus the negative correlation is verified. Based on the ImageNet
                dataset, we generated adversarial perturbations on ResNet-34/152 (RN-34/152) and DenseNet-121/201
                (DN-121/201), respectively, and transferred adversarial perturbations generated on each ResNet to
                DenseNets. Similarly, we also transferred adversarial perturbations generated on each DenseNet to
                ResNets. Figure 1 shows the negative correlation between adversarial transferability and game-theoretic
                interaction, where the horizontal axis indicates the average interaction of adversarial perturbations
                through all testing images, and the vertical axis represents the average transfer utility of adversarial
                perturbations on the target DNN.</p>
            <figure class="p-0 text-center">
                <img src="./blog-post/img/chapter-7/fig1.jpg" width="80%">
                <figcaption class="pt-3 px-5 card-img-bottom">
                    <p class="text-muted font-italic">
                        Figure 1. The negative correlation between the transfer utility and the interaction. The
                        correlation is
                        computed as the Pearson correlation. The blue shade in each subfigure represents the 95%
                        confidence interval of the linear regression.</p>
                </figcaption>
            </figure>
            <h4><strong>A unified explanation: Reducing game-theoretic interaction is the common effects of various
                    transferability-boosting methods</strong></h4>
            <p>Beginning from the negative correlation between adversarial transferability and game-theoretic
                interaction, we extracted the common effective component from various previous methods of enhancing
                adversarial transferability, which is reducing game-theoretic interactions inside the adversarial
                perturbation. We find that although the starting points and implementations of previous approaches to
                enhance adversarial transferability are different, they all share the same effects - they all reduce the
                game-theoretic interaction inside the adversarial perturbation during the attack. We theoretically
                demonstrate that VR Attack, MI Attack, and SGM Attack produce adversarial perturbations with lower
                interactions than the most common baseline (PGD Attack); we experimentally verify that DI Attack and TI
                Attack reduce the interaction between perturbations.</p>
            <figure class="p-0 text-center">
                <img src="./blog-post/img/chapter-7/fig2.jpg" width="80%">
                <!-- <figcaption class="pt-3 px-5 card-img-bottom">
                    <p class="text-muted font-italic">
                        Figure 2. The research.</p>
                </figcaption> -->
            </figure>
            <h4><strong>Verification: Effectiveness of reducing game interactions</strong></h4>
            <p>To further verify the negative correlation between the game-theoretic interaction and adversarial
                transferability, we propose a loss function based on the game-theoretic interaction - directly
                penalizing the interaction inside the perturbation in the attack. We optimize both the classification
                loss function and the interaction-based loss function to generate the adversarial perturbation, which is
                called the Interaction-Reduced Attack (IR Attack).</p>
            <!-- formula -->
            \begin{equation}
            \max _{\delta}\left[\ell(h(x+\delta), y)-\lambda \ell_{\text {interaction }}\right], \quad \ell_{\text
            {interaction }}=\mathbb{E}_{i, j}\left[I_{i j}(\delta)\right] \quad \text { s.t. }\|\delta\|_{p} \leq
            \epsilon, x+\delta \in[0,1]^{n}
            \end{equation}
            <p>Experimental results show that the interaction-based loss function can significantly improve the
                transferability of the adversarial perturbation. As shown in Table 1, compared with baseline methods,
                the interaction loss function improves the transferability of adversarial examples by 8.2%~35.4%. It is
                worth noting that the interaction loss is only a direct measure to reduce the game-theoretic
                interaction, and we can combine it with previous attacks that reduce the interaction inside the
                perturbation to jointly reduce the interaction inside the perturbations to further improve the
                adversarial transferability. Therefore, we propose HybridIR Attack (MI+VR+SGM+IR Attack). In our
                experiments, the HybridIR Attack increases the transferability of the adversarial examples from
                54.6%~98.8% to 70.2%~99.1%.</p>
            <figure class="p-0 text-center">
                <figcaption class="pt-3 px-5 card-img-bottom">
                    <p class="text-muted font-italic">
                        Table 1: The success rates of \( L_1 \) and \( L_\infty \) black-box attacks crafted on six
                        source models,
                        including AlexNet, VGG16, RN-34/152, DN-121/201, against seven target models. Transferability of
                        adversarial perturbations can be enhanced by penalizing interactions.</p>
                </figcaption>
                <img src="./blog-post/img/chapter-7/table1.png" width="80%">

            </figure>
            <figure class="p-0 text-center">
                <figcaption class="pt-3 px-5 card-img-bottom">
                    <p class="text-muted font-italic">
                        Table 2: The success rates of \( L_\infty \) black-box attacks crafted on the ensemble model
                        (RN-34+RN-
                        152+DN-121) against nine target models.</p>
                </figcaption>
                <img src="./blog-post/img/chapter-7/table2.png" width="80%">
            </figure>
        </div>

    </section>

    <!-- contact -->
    <section id="contact" class="bg-dark bg-gradient text-center text-white pb-5 px-5">
        <div class="footer bg-dark-gradient">
            <div class="container">

                <img src="http://en.sjtu.edu.cn/images/logo_white.png" alt=""
                    style="max-width:100%;max-height:50px;margin-bottom:0px;margin-top:10px;">
                <div class="row p-0" style="vertical-align:middle">
                    <div class="col-lg-3">
                        <h3>Address</h3>
                        <p> 800 Dongchuan RD. Minhang District, Shanghai, China
                            <br> 上海市闵行区东川路800号
                        </p>
                    </div>
                    <div class="col-lg-3">
                        <h3>Email </h3>
                        <p>zqs1022@sjtu.edu.cn</p>
                    </div>
                    <div class="col-lg-3">
                        <h3> Follow us</h3>
                        <p> media platform</p>
                        <div class="row">
                            <div class="media-list">
                                <p>
                                    <span>
                                        <a href="https://github.com/sjtu-XAI-lab"><i class="fab fa-github"
                                                style="font-size: 20px;"></i></a>
                                        <a href="https://twitter.com/QuanshiZ"> <i class="fab fa-twitter"
                                                style="font-size: 20px;"></i>
                                        </a>

                                        <a href="https://www.youtube.com/user/zqs1022/featured">
                                            <i class="fab fa-youtube" style="font-size: 20px;"></i>
                                        </a>
                                        <a href="https://www.baidu.com">
                                            <i class="fab fa-zhihu big-icon" style="font-size: 20px;"></i>
                                        </a>
                                        <a href="https://www.baidu.com">
                                            <i class="fab fa-weixin big-icon" style="font-size: 20px;"></i>
                                        </a>
                                    </span>
                                </p>

                            </div>

                        </div>
                    </div>
                    <div class="col-lg-3">
                        <center>
                            <div align="center" style="width:30%">
                                <script type="text/javascript" id="clstr_globe"
                                    src="//clustrmaps.com/globe.js?d=ZFAQauiNfOzaVSFWRxGPxdiZ5f0oN235Jn4ihTE3hsw"></script>
                            </div>
                        </center>
                        This page has been visited for
                        <a href="https://www.easycounter.com/">
                            <img src="https://www.easycounter.com/counter.php?gszfwsb" border="0"
                                alt="HTML Hit Counter"></a> times
                    </div>
                </div>
            </div>
        </div>
        <button onclick="topFunction()" id="myBtn" title="Go to top" class="bg-dark bg-gradient">Top</button>
        <style>
            #myBtn {
                display: none;
                position: fixed;
                bottom: 60px;
                right: 30px;
                z-index: 99;
                border: none;
                outline: none;
                color: white;
                cursor: pointer;
                height: 50px;
                width: 50px;
                border-radius: 50%;
                font-weight: bold;
            }

            #myBtn:hover {
                background-color: #000;
            }
        </style>
    </section>

    <footer class="bg-dark bg-gradient text-center text-white fixed-bottom p-0">
        <p class="text-white">Copyright &copy; 2022. Lab for Interpretability and Theory-Driven Deep Learning. All
            rights reserved.</p>
    </footer>


    <script text="text/javascript">
        window.onscroll = function () { scrollFunction() };
        function scrollFunction() {
            if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
                document.getElementById("myBtn").style.display = "block";
            } else {
                document.getElementById("myBtn").style.display = "none";
            }
        }
        function topFunction() {
            document.body.scrollTop = 0;
            document.documentElement.scrollTop = 0;
        }
    </script>

    <!-- JavaScript Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js"
        integrity="sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13"
        crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
        crossorigin="anonymous"></script>
    <script src="go-debug.js"></script>
    <script src="HyperlinkText.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <!-- <script text="text/javascript" src="test.js"></script> -->
    <script text="text/javascript" src="interaction-map.js"></script>
    <script text="text/javascript" src="test-1.js"></script>
    <script text="text/javascript" src="test-2.js"></script>
    <script type="text/javascript" id="clstr_globe"
        src="//clustrmaps.com/globe.js?d=ZFAQauiNfOzaVSFWRxGPxdiZ5f0oN235Jn4ihTE3hsw"></script>
</body>

</html>